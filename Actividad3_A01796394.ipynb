{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc888fd2-a7e8-4c78-ad7e-e23a58506e0b",
   "metadata": {},
   "source": [
    "# Actividad 3. - Aprendizaje supervisado y no supervisado\"\n",
    "# Alumno: Víctor Eduardo Pérez Aguilar, Matricula: A01796394\n",
    "\n",
    "# Parte 1.\n",
    "\n",
    "## Introducción Teórica\n",
    "\n",
    "Machine learning es una rama de la inteligencia artificial que busca que las computadoras aprendan a partir de datos para tomar decisiones o hacer predicciones, sin que tengamos que programarlas paso a paso para cada tarea. Es como enseñarles a “aprender” de la experiencia, tal como lo hacemos los humanos.\n",
    "\n",
    "Dentro del aprendizaje automático, existen dos enfoques principales:\n",
    "\n",
    "- **Aprendizaje supervisado**\n",
    "- **Aprendizaje no supervisado**\n",
    "\n",
    "---\n",
    "\n",
    "## Aprendizaje Supervisado\n",
    "\n",
    "En el aprendizaje supervisado, le damos al modelo un conjunto de datos donde ya conocemos la respuesta correcta: es decir, tenemos las entradas (las características) y las salidas esperadas (las etiquetas). El objetivo es que el modelo descubra cómo relacionar esas entradas con las salidas para luego poder predecir resultados cuando reciba datos nuevos que no ha visto antes.\n",
    "\n",
    "Algunos algoritmos comunes en este tipo de aprendizaje son:\n",
    "\n",
    "- **Decision Tree:** Funcionan como un árbol de preguntas que ayudan a clasificar o predecir un resultado.\n",
    "- **Random Forest:** Son un conjunto de árboles de decisión que trabajan juntos para mejorar la precisión y evitar errores.\n",
    "- **GBTClassifier:** Construye varios árboles uno tras otro, donde cada árbol intenta corregir los errores del anterior.\n",
    "- **Multilayer Perceptron:** Es una red neuronal con varias capas que puede capturar relaciones complejas y no lineales entre las variables.\n",
    "\n",
    "---\n",
    "\n",
    "## Aprendizaje No Supervisado\n",
    "\n",
    "En este caso, el modelo recibe solo los datos de entrada, sin saber las respuestas correctas. La idea es que el modelo encuentre patrones, agrupaciones o estructuras escondidas dentro de esos datos.\n",
    "\n",
    "Algunos algoritmos populares para este enfoque son:\n",
    "\n",
    "- **K-means:** Agrupa los datos en “k” grupos basados en qué tan similares son entre sí.\n",
    "- **Gaussian Mixture:** Supone que los datos vienen de varias distribuciones gaussianas mezcladas, lo que permite una agrupación más flexible.\n",
    "- **Power Iteration Clustering:** Utiliza técnicas matemáticas avanzadas para agrupar datos según su similitud.\n",
    "\n",
    "---\n",
    "\n",
    "## Algoritmos en PySpark\n",
    "\n",
    "PySpark nos ayuda a procesar grandes volúmenes de datos de forma rápida y distribuida.\n",
    "\n",
    "Dentro de PySpark está la biblioteca **MLlib**, que incluye implementaciones de muchos de los algoritmos que mencionamos, tanto para aprendizaje supervisado como no supervisado. Esto hace que sea mucho más fácil trabajar con grandes conjuntos de datos y crear modelos eficientes.\n",
    "\n",
    "Algoritmos que puedes usar en PySpark son:\n",
    "\n",
    "- Árboles de decisión: DecisionTreeClassifier.\n",
    "- Bosques aleatorios: RandomForestClassifier.\n",
    "- Clasificador Boosted por Gradiente: GBTClassifier.\n",
    "- Perceptrón multicapa: MultilayerPerceptronClassifier.\n",
    "- K-means\n",
    "- Gaussian Mixture\n",
    "- Power Iteration Clustering (PIC)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac785ce-6c23-4719-8a6e-97ebb99964b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/05/25 10:16:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El archivo existe: /Users/vpereza/Downloads/DataSetCrimeChicago/Chicago_Crimes_-_2001_to_Present.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Inicia una sesión de Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Leer CSV Localmente\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verifica si el archivo existe en la ruta proporcionada\n",
    "ruta_archivo = \"/Users/vpereza/Downloads/DataSetCrimeChicago/Chicago_Crimes_-_2001_to_Present.csv\"\n",
    "if os.path.exists(ruta_archivo):\n",
    "    print(f\"El archivo existe: {ruta_archivo}\")\n",
    "else:\n",
    "    print(f\"El archivo no se encuentra en la ruta: {ruta_archivo}\")\n",
    "\n",
    "# Lee el archivo CSV en un DataFrame de Spark\n",
    "df = spark.read.option(\"header\", \"true\").option(\"inferSchema\", \"true\").csv(ruta_archivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e37b89fd-53b4-4837-831f-c7734ff0c0b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/25 10:16:28 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Chicago Crimes Analysis\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21019a45-a09e-4ca7-8b29-3f5fa86cb6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros: 7811711\n",
      "Número de columnas: 22\n",
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: boolean (nullable = true)\n",
      " |-- Domestic: boolean (nullable = true)\n",
      " |-- Beat: integer (nullable = true)\n",
      " |-- District: integer (nullable = true)\n",
      " |-- Ward: integer (nullable = true)\n",
      " |-- Community Area: integer (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: integer (nullable = true)\n",
      " |-- Y Coordinate: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Updated On: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/25 10:16:32 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|summary|                ID|       Case Number|                Date|         Block|              IUCR|     Primary Type|    Description|Location Description|              Beat|          District|              Ward|    Community Area|          FBI Code|     X Coordinate|      Y Coordinate|              Year|          Updated On|           Latitude|           Longitude|            Location|\n",
      "+-------+------------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "|  count|           7811711|           7811707|             7811711|       7811711|           7811711|          7811711|        7811711|             7801153|           7811711|           7811664|           7196863|           7198235|           7811711|          7724246|           7724246|           7811711|             7811711|            7724246|             7724246|             7724246|\n",
      "|   mean|  7047235.09462818|314071.94444444444|                NULL|          NULL|1120.9696163074661|             NULL|           NULL|                NULL|1185.8247616943331|11.294905029197364| 22.75510913574428|  37.4813988429108|12.077565887306832|1164603.286751354|1885786.9657176894|2009.9892941507949|                NULL|  41.84219488113005|  -87.67148557998773|                NULL|\n",
      "| stddev|3514586.1451125084|  132968.524780014|                NULL|          NULL| 811.5586530819171|             NULL|           NULL|                NULL| 703.1754648166113| 6.953115491876338|13.850822546678101|21.541659607513346|  7.30851801814186|16840.02517325935|32267.013002939297| 6.296393348513412|                NULL|0.08877275492270253|0.061061439033470145|                NULL|\n",
      "|    min|               634|         .JB299184|01/01/2001 01:00:...|0000X E 100 PL|              0110|            ARSON| $300 AND UNDER|\"CTA \"\"L\"\" PLATFORM\"|               111|                 1|                 1|                 0|               01A|                0|                 0|              2001|01/01/2007 07:32:...|       36.619446395|       -91.686565684|(36.619446395, -9...|\n",
      "|    max|          13096706|         ZZZ199957|12/31/2022 12:59:...|   XX  UNKNOWN|              9901|WEAPONS VIOLATION|WIREROOM/SPORTS|                YMCA|              2535|                31|                50|                77|                26|          1205119|           1951622|              2023|12/31/2022 03:54:...|       42.022910333|       -87.524529378|(42.022910333, -8...|\n",
      "+-------+------------------+------------------+--------------------+--------------+------------------+-----------------+---------------+--------------------+------------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+--------------------+-------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 8:============================================>            (11 + 3) / 14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
      "| ID|Case Number|Date|Block|IUCR|Primary Type|Description|Location Description|Arrest|Domestic|Beat|District|  Ward|Community Area|FBI Code|X Coordinate|Y Coordinate|Year|Updated On|Latitude|Longitude|Location|\n",
      "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
      "|  0|          4|   0|    0|   0|           0|          0|               10558|     0|       0|   0|      47|614848|        613476|       0|       87465|       87465|   0|         0|   87465|    87465|   87465|\n",
      "+---+-----------+----+-----+----+------------+-----------+--------------------+------+--------+----+--------+------+--------------+--------+------------+------------+----+----------+--------+---------+--------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Número de registros y columnas\n",
    "num_registros = df.count()\n",
    "num_columnas = len(df.columns)\n",
    "\n",
    "print(f\"Número de registros: {num_registros}\")\n",
    "print(f\"Número de columnas: {num_columnas}\")\n",
    "\n",
    "# Tipos de datos de cada columna\n",
    "df.printSchema()\n",
    "\n",
    "# Ver las estadísticas generales de las columnas numéricas\n",
    "df.describe().show()\n",
    "\n",
    "# Identificar valores faltantes (nulos) en cada columna\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "# Crear una lista de expresiones para contar los valores nulos en cada columna\n",
    "nulos_por_columna = [sum(col(c).isNull().cast(\"int\")).alias(c) for c in df.columns]\n",
    "\n",
    "# Realizar la agregación para contar los nulos por columna\n",
    "df.select(nulos_por_columna).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d16e7c-8507-4c51-9e4d-23d809414d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 91:========================================>               (10 + 4) / 14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------------+\n",
      "|       Columna        | Valores Nulos |\n",
      "+----------------------+---------------+\n",
      "|          ID          |       0       |\n",
      "|     Case Number      |       4       |\n",
      "|         Date         |       0       |\n",
      "|        Block         |       0       |\n",
      "|         IUCR         |       0       |\n",
      "|     Primary Type     |       0       |\n",
      "|     Description      |       0       |\n",
      "| Location Description |     10558     |\n",
      "|        Arrest        |       0       |\n",
      "|       Domestic       |       0       |\n",
      "|         Beat         |       0       |\n",
      "|       District       |       47      |\n",
      "|         Ward         |     614848    |\n",
      "|    Community Area    |     613476    |\n",
      "|       FBI Code       |       0       |\n",
      "|     X Coordinate     |     87465     |\n",
      "|     Y Coordinate     |     87465     |\n",
      "|         Year         |       0       |\n",
      "|      Updated On      |       0       |\n",
      "|       Latitude       |     87465     |\n",
      "|      Longitude       |     87465     |\n",
      "|       Location       |     87465     |\n",
      "+----------------------+---------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Crear la tabla de PrettyTable\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Columna\", \"Valores Nulos\"]\n",
    "\n",
    "# Revisar valores nulos y agregarlos a la tabla\n",
    "for column in df.columns:\n",
    "    null_count = df.filter(col(column).isNull()).count()\n",
    "    table.add_row([column, null_count])\n",
    "\n",
    "# Imprimir la tabla con los valores nulos\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7a2ed17-f9c7-4f0a-bdb5-32d52b583ea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/04/27 15:43:01 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear una configuración de Spark\n",
    "conf = SparkConf().set(\"spark.sql.warehouse.dir\", \"/path/to/your/warehouse\")\n",
    "\n",
    "# Deshabilitar los warnings\n",
    "conf.set(\"spark.ui.showConsoleProgress\", \"false\")\n",
    "\n",
    "# Crear la sesión Spark con la configuración\n",
    "spark = SparkSession.builder.config(conf=conf).getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e116690-0ab7-4a25-b979-43e204872094",
   "metadata": {},
   "source": [
    "## Caracterización Estadística de las Variables\n",
    "\n",
    "- **Identificadores** (ID, Case Number): Son campos únicos que permiten distinguir cada registro, pero no aportan valor analítico, por lo que se excluyen del análisis estadístico.\n",
    "- **Fechas** (Date, Year): Se analizan considerando rango, frecuencias y tendencias por año o mes.\n",
    "- **Variables categóricas** (Primary Type, Location Description): Se reportan frecuencias absolutas y relativas, moda y el número de categorías distintas.\n",
    "- **Booleanas** (Arrest, Domestic): Se muestran proporciones de verdadero/falso.\n",
    "- **Numéricas discretas** (District, Ward, Beat, Community Area): Se calculan media, moda, mínimo, máximo y número de valores únicos.\n",
    "- **Numéricas continuas** (Latitude, Longitude, X/Y Coordinate): Se reportan media, desviación estándar, mínimo y máximo, reflejando la distribución geoespacial de los datos.\n",
    "\n",
    "Este análisis permite entender el comportamiento general del conjunto de datos y fundamenta las fases de particionamiento y muestreo de la investigación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5de3819-abc6-435e-85c9-ed7cb658f7b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_cfa80\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cfa80_level0_col0\" class=\"col_heading level0 col0\" >0</th>\n",
       "      <th id=\"T_cfa80_level0_col1\" class=\"col_heading level0 col1\" >1</th>\n",
       "      <th id=\"T_cfa80_level0_col2\" class=\"col_heading level0 col2\" >2</th>\n",
       "      <th id=\"T_cfa80_level0_col3\" class=\"col_heading level0 col3\" >3</th>\n",
       "      <th id=\"T_cfa80_level0_col4\" class=\"col_heading level0 col4\" >4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row0\" class=\"row_heading level0 row0\" >summary</th>\n",
       "      <td id=\"T_cfa80_row0_col0\" class=\"data row0 col0\" >count</td>\n",
       "      <td id=\"T_cfa80_row0_col1\" class=\"data row0 col1\" >mean</td>\n",
       "      <td id=\"T_cfa80_row0_col2\" class=\"data row0 col2\" >stddev</td>\n",
       "      <td id=\"T_cfa80_row0_col3\" class=\"data row0 col3\" >min</td>\n",
       "      <td id=\"T_cfa80_row0_col4\" class=\"data row0 col4\" >max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row1\" class=\"row_heading level0 row1\" >ID</th>\n",
       "      <td id=\"T_cfa80_row1_col0\" class=\"data row1 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row1_col1\" class=\"data row1 col1\" >7047235.09462818</td>\n",
       "      <td id=\"T_cfa80_row1_col2\" class=\"data row1 col2\" >3514586.1451125084</td>\n",
       "      <td id=\"T_cfa80_row1_col3\" class=\"data row1 col3\" >634</td>\n",
       "      <td id=\"T_cfa80_row1_col4\" class=\"data row1 col4\" >13096706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row2\" class=\"row_heading level0 row2\" >Case Number</th>\n",
       "      <td id=\"T_cfa80_row2_col0\" class=\"data row2 col0\" >7811707</td>\n",
       "      <td id=\"T_cfa80_row2_col1\" class=\"data row2 col1\" >314071.94444444444</td>\n",
       "      <td id=\"T_cfa80_row2_col2\" class=\"data row2 col2\" >132968.524780014</td>\n",
       "      <td id=\"T_cfa80_row2_col3\" class=\"data row2 col3\" >.JB299184</td>\n",
       "      <td id=\"T_cfa80_row2_col4\" class=\"data row2 col4\" >ZZZ199957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row3\" class=\"row_heading level0 row3\" >Date</th>\n",
       "      <td id=\"T_cfa80_row3_col0\" class=\"data row3 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row3_col1\" class=\"data row3 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row3_col2\" class=\"data row3 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row3_col3\" class=\"data row3 col3\" >01/01/2001 01:00:00 AM</td>\n",
       "      <td id=\"T_cfa80_row3_col4\" class=\"data row3 col4\" >12/31/2022 12:59:00 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row4\" class=\"row_heading level0 row4\" >Block</th>\n",
       "      <td id=\"T_cfa80_row4_col0\" class=\"data row4 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row4_col1\" class=\"data row4 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row4_col2\" class=\"data row4 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row4_col3\" class=\"data row4 col3\" >0000X E 100 PL</td>\n",
       "      <td id=\"T_cfa80_row4_col4\" class=\"data row4 col4\" >XX  UNKNOWN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row5\" class=\"row_heading level0 row5\" >IUCR</th>\n",
       "      <td id=\"T_cfa80_row5_col0\" class=\"data row5 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row5_col1\" class=\"data row5 col1\" >1120.9696163074661</td>\n",
       "      <td id=\"T_cfa80_row5_col2\" class=\"data row5 col2\" >811.5586530819171</td>\n",
       "      <td id=\"T_cfa80_row5_col3\" class=\"data row5 col3\" >0110</td>\n",
       "      <td id=\"T_cfa80_row5_col4\" class=\"data row5 col4\" >9901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row6\" class=\"row_heading level0 row6\" >Primary Type</th>\n",
       "      <td id=\"T_cfa80_row6_col0\" class=\"data row6 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row6_col1\" class=\"data row6 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row6_col2\" class=\"data row6 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row6_col3\" class=\"data row6 col3\" >ARSON</td>\n",
       "      <td id=\"T_cfa80_row6_col4\" class=\"data row6 col4\" >WEAPONS VIOLATION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row7\" class=\"row_heading level0 row7\" >Description</th>\n",
       "      <td id=\"T_cfa80_row7_col0\" class=\"data row7 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row7_col1\" class=\"data row7 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row7_col2\" class=\"data row7 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row7_col3\" class=\"data row7 col3\" >$300 AND UNDER</td>\n",
       "      <td id=\"T_cfa80_row7_col4\" class=\"data row7 col4\" >WIREROOM/SPORTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row8\" class=\"row_heading level0 row8\" >Location Description</th>\n",
       "      <td id=\"T_cfa80_row8_col0\" class=\"data row8 col0\" >7801153</td>\n",
       "      <td id=\"T_cfa80_row8_col1\" class=\"data row8 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row8_col2\" class=\"data row8 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row8_col3\" class=\"data row8 col3\" >\"CTA \"\"L\"\" PLATFORM\"</td>\n",
       "      <td id=\"T_cfa80_row8_col4\" class=\"data row8 col4\" >YMCA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row9\" class=\"row_heading level0 row9\" >Beat</th>\n",
       "      <td id=\"T_cfa80_row9_col0\" class=\"data row9 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row9_col1\" class=\"data row9 col1\" >1185.8247616943331</td>\n",
       "      <td id=\"T_cfa80_row9_col2\" class=\"data row9 col2\" >703.1754648166113</td>\n",
       "      <td id=\"T_cfa80_row9_col3\" class=\"data row9 col3\" >111</td>\n",
       "      <td id=\"T_cfa80_row9_col4\" class=\"data row9 col4\" >2535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row10\" class=\"row_heading level0 row10\" >District</th>\n",
       "      <td id=\"T_cfa80_row10_col0\" class=\"data row10 col0\" >7811664</td>\n",
       "      <td id=\"T_cfa80_row10_col1\" class=\"data row10 col1\" >11.294905029197364</td>\n",
       "      <td id=\"T_cfa80_row10_col2\" class=\"data row10 col2\" >6.953115491876338</td>\n",
       "      <td id=\"T_cfa80_row10_col3\" class=\"data row10 col3\" >1</td>\n",
       "      <td id=\"T_cfa80_row10_col4\" class=\"data row10 col4\" >31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row11\" class=\"row_heading level0 row11\" >Ward</th>\n",
       "      <td id=\"T_cfa80_row11_col0\" class=\"data row11 col0\" >7196863</td>\n",
       "      <td id=\"T_cfa80_row11_col1\" class=\"data row11 col1\" >22.75510913574428</td>\n",
       "      <td id=\"T_cfa80_row11_col2\" class=\"data row11 col2\" >13.850822546678101</td>\n",
       "      <td id=\"T_cfa80_row11_col3\" class=\"data row11 col3\" >1</td>\n",
       "      <td id=\"T_cfa80_row11_col4\" class=\"data row11 col4\" >50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row12\" class=\"row_heading level0 row12\" >Community Area</th>\n",
       "      <td id=\"T_cfa80_row12_col0\" class=\"data row12 col0\" >7198235</td>\n",
       "      <td id=\"T_cfa80_row12_col1\" class=\"data row12 col1\" >37.4813988429108</td>\n",
       "      <td id=\"T_cfa80_row12_col2\" class=\"data row12 col2\" >21.541659607513346</td>\n",
       "      <td id=\"T_cfa80_row12_col3\" class=\"data row12 col3\" >0</td>\n",
       "      <td id=\"T_cfa80_row12_col4\" class=\"data row12 col4\" >77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row13\" class=\"row_heading level0 row13\" >FBI Code</th>\n",
       "      <td id=\"T_cfa80_row13_col0\" class=\"data row13 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row13_col1\" class=\"data row13 col1\" >12.077565887306832</td>\n",
       "      <td id=\"T_cfa80_row13_col2\" class=\"data row13 col2\" >7.30851801814186</td>\n",
       "      <td id=\"T_cfa80_row13_col3\" class=\"data row13 col3\" >01A</td>\n",
       "      <td id=\"T_cfa80_row13_col4\" class=\"data row13 col4\" >26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row14\" class=\"row_heading level0 row14\" >X Coordinate</th>\n",
       "      <td id=\"T_cfa80_row14_col0\" class=\"data row14 col0\" >7724246</td>\n",
       "      <td id=\"T_cfa80_row14_col1\" class=\"data row14 col1\" >1164603.286751354</td>\n",
       "      <td id=\"T_cfa80_row14_col2\" class=\"data row14 col2\" >16840.02517325935</td>\n",
       "      <td id=\"T_cfa80_row14_col3\" class=\"data row14 col3\" >0</td>\n",
       "      <td id=\"T_cfa80_row14_col4\" class=\"data row14 col4\" >1205119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row15\" class=\"row_heading level0 row15\" >Y Coordinate</th>\n",
       "      <td id=\"T_cfa80_row15_col0\" class=\"data row15 col0\" >7724246</td>\n",
       "      <td id=\"T_cfa80_row15_col1\" class=\"data row15 col1\" >1885786.9657176894</td>\n",
       "      <td id=\"T_cfa80_row15_col2\" class=\"data row15 col2\" >32267.013002939297</td>\n",
       "      <td id=\"T_cfa80_row15_col3\" class=\"data row15 col3\" >0</td>\n",
       "      <td id=\"T_cfa80_row15_col4\" class=\"data row15 col4\" >1951622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row16\" class=\"row_heading level0 row16\" >Year</th>\n",
       "      <td id=\"T_cfa80_row16_col0\" class=\"data row16 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row16_col1\" class=\"data row16 col1\" >2009.9892941507949</td>\n",
       "      <td id=\"T_cfa80_row16_col2\" class=\"data row16 col2\" >6.296393348513412</td>\n",
       "      <td id=\"T_cfa80_row16_col3\" class=\"data row16 col3\" >2001</td>\n",
       "      <td id=\"T_cfa80_row16_col4\" class=\"data row16 col4\" >2023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row17\" class=\"row_heading level0 row17\" >Updated On</th>\n",
       "      <td id=\"T_cfa80_row17_col0\" class=\"data row17 col0\" >7811711</td>\n",
       "      <td id=\"T_cfa80_row17_col1\" class=\"data row17 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row17_col2\" class=\"data row17 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row17_col3\" class=\"data row17 col3\" >01/01/2007 07:32:02 AM</td>\n",
       "      <td id=\"T_cfa80_row17_col4\" class=\"data row17 col4\" >12/31/2022 03:54:39 PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row18\" class=\"row_heading level0 row18\" >Latitude</th>\n",
       "      <td id=\"T_cfa80_row18_col0\" class=\"data row18 col0\" >7724246</td>\n",
       "      <td id=\"T_cfa80_row18_col1\" class=\"data row18 col1\" >41.84219488113005</td>\n",
       "      <td id=\"T_cfa80_row18_col2\" class=\"data row18 col2\" >0.08877275492270253</td>\n",
       "      <td id=\"T_cfa80_row18_col3\" class=\"data row18 col3\" >36.619446395</td>\n",
       "      <td id=\"T_cfa80_row18_col4\" class=\"data row18 col4\" >42.022910333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row19\" class=\"row_heading level0 row19\" >Longitude</th>\n",
       "      <td id=\"T_cfa80_row19_col0\" class=\"data row19 col0\" >7724246</td>\n",
       "      <td id=\"T_cfa80_row19_col1\" class=\"data row19 col1\" >-87.67148557998773</td>\n",
       "      <td id=\"T_cfa80_row19_col2\" class=\"data row19 col2\" >0.061061439033470145</td>\n",
       "      <td id=\"T_cfa80_row19_col3\" class=\"data row19 col3\" >-91.686565684</td>\n",
       "      <td id=\"T_cfa80_row19_col4\" class=\"data row19 col4\" >-87.524529378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cfa80_level0_row20\" class=\"row_heading level0 row20\" >Location</th>\n",
       "      <td id=\"T_cfa80_row20_col0\" class=\"data row20 col0\" >7724246</td>\n",
       "      <td id=\"T_cfa80_row20_col1\" class=\"data row20 col1\" >None</td>\n",
       "      <td id=\"T_cfa80_row20_col2\" class=\"data row20 col2\" >None</td>\n",
       "      <td id=\"T_cfa80_row20_col3\" class=\"data row20 col3\" >(36.619446395, -91.686565684)</td>\n",
       "      <td id=\"T_cfa80_row20_col4\" class=\"data row20 col4\" >(42.022910333, -87.677192004)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x16e190bf0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_pandas_T = df_pandas.T\n",
    "display(df_pandas_T.style.background_gradient(cmap='YlOrRd'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f112e76-ef33-4bba-bfd1-b618fc5a7a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Únicos en 'IUCR':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT IUCR)|\n",
      "+--------------------+\n",
      "|                 404|\n",
      "+--------------------+\n",
      "\n",
      "Únicos en 'Primary Type':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+\n",
      "|count(DISTINCT Primary Type)|\n",
      "+----------------------------+\n",
      "|                          36|\n",
      "+----------------------------+\n",
      "\n",
      "Únicos en 'Description':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+\n",
      "|count(DISTINCT Description)|\n",
      "+---------------------------+\n",
      "|                        546|\n",
      "+---------------------------+\n",
      "\n",
      "Únicos en 'Location Description':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+\n",
      "|count(DISTINCT Location Description)|\n",
      "+------------------------------------+\n",
      "|                                 216|\n",
      "+------------------------------------+\n",
      "\n",
      "Únicos en 'Beat':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Beat)|\n",
      "+--------------------+\n",
      "|                 305|\n",
      "+--------------------+\n",
      "\n",
      "Únicos en 'District':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT District)|\n",
      "+------------------------+\n",
      "|                      24|\n",
      "+------------------------+\n",
      "\n",
      "Únicos en 'Ward':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|count(DISTINCT Ward)|\n",
      "+--------------------+\n",
      "|                  50|\n",
      "+--------------------+\n",
      "\n",
      "Únicos en 'Community Area':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|count(DISTINCT Community Area)|\n",
      "+------------------------------+\n",
      "|                            78|\n",
      "+------------------------------+\n",
      "\n",
      "Únicos en 'FBI Code':\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 142:=======================================>               (10 + 4) / 14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT FBI Code)|\n",
      "+------------------------+\n",
      "|                      26|\n",
      "+------------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct\n",
    "\n",
    "columnas = [\n",
    "    \"IUCR\", \n",
    "    \"Primary Type\", \n",
    "    \"Description\", \n",
    "    \"Location Description\", \n",
    "    \"Beat\", \n",
    "    \"District\", \n",
    "    \"Ward\", \n",
    "    \"Community Area\", \n",
    "    \"FBI Code\"\n",
    "]\n",
    "\n",
    "for colname in columnas:\n",
    "    print(f\"Únicos en '{colname}':\")\n",
    "    df.select(countDistinct(colname)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f57906e-df41-4759-83b4-3e76d2c8be0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Description:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+------+\n",
      "|Description                 |count |\n",
      "+----------------------------+------+\n",
      "|SIMPLE                      |916750|\n",
      "|$500 AND UNDER              |632821|\n",
      "|DOMESTIC BATTERY SIMPLE     |610676|\n",
      "|TO VEHICLE                  |434447|\n",
      "|OVER $500                   |416786|\n",
      "|TO PROPERTY                 |411525|\n",
      "|AUTOMOBILE                  |299471|\n",
      "|FORCIBLE ENTRY              |284651|\n",
      "|POSS: CANNABIS 30GMS OR LESS|278139|\n",
      "|FROM BUILDING               |255295|\n",
      "+----------------------------+------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Top 10 Location Description:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+-------+\n",
      "|Location Description          |count  |\n",
      "+------------------------------+-------+\n",
      "|STREET                        |2034594|\n",
      "|RESIDENCE                     |1309164|\n",
      "|APARTMENT                     |884477 |\n",
      "|SIDEWALK                      |730172 |\n",
      "|OTHER                         |270019 |\n",
      "|PARKING LOT/GARAGE(NON.RESID.)|202991 |\n",
      "|ALLEY                         |173490 |\n",
      "|SMALL RETAIL STORE            |147978 |\n",
      "|SCHOOL, PUBLIC, BUILDING      |146387 |\n",
      "|RESIDENCE-GARAGE              |135543 |\n",
      "+------------------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n",
      "Top 10 Primary Type:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 154:===========================================>           (11 + 3) / 14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|Primary Type       |count  |\n",
      "+-------------------+-------+\n",
      "|THEFT              |1647915|\n",
      "|BATTERY            |1427736|\n",
      "|CRIMINAL DAMAGE    |890391 |\n",
      "|NARCOTICS          |748161 |\n",
      "|ASSAULT            |509714 |\n",
      "|OTHER OFFENSE      |485121 |\n",
      "|BURGLARY           |425159 |\n",
      "|MOTOR VEHICLE THEFT|378395 |\n",
      "|DECEPTIVE PRACTICE |346770 |\n",
      "|ROBBERY            |293311 |\n",
      "+-------------------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Top 10 DESCRIPTIONS\n",
    "print(\"Top 10 Description:\")\n",
    "df.groupBy(\"Description\").count().orderBy(col(\"count\").desc()).show(10, truncate=False)\n",
    "\n",
    "# Top 10 LOCATION DESCRIPTION\n",
    "print(\"Top 10 Location Description:\")\n",
    "df.groupBy(\"Location Description\").count().orderBy(col(\"count\").desc()).show(10, truncate=False)\n",
    "\n",
    "# Top 10 PRIMARY TYPE\n",
    "print(\"Top 10 Primary Type:\")\n",
    "df.groupBy(\"Primary Type\").count().orderBy(col(\"count\").desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "303c7868-419b-485d-9b75-1deefa10b964",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Frecuencias de Arrest:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+----------+\n",
      "|Arrest|  count|porcentaje|\n",
      "+------+-------+----------+\n",
      "| false|5773604|     73.91|\n",
      "|  true|2038107|     26.09|\n",
      "+------+-------+----------+\n",
      "\n",
      "\n",
      "Frecuencias de Domestic:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 229:=======================================>               (10 + 4) / 14]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------+----------+\n",
      "|Domestic|  count|porcentaje|\n",
      "+--------+-------+----------+\n",
      "|   false|6730624|     86.16|\n",
      "|    true|1081087|     13.84|\n",
      "+--------+-------+----------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, round\n",
    "\n",
    "total = df.count()\n",
    "\n",
    "for colname in [\"Arrest\", \"Domestic\"]:\n",
    "    print(f\"\\nFrecuencias de {colname}:\")\n",
    "    # Absolutas y relativas\n",
    "    df.groupBy(colname).count()\\\n",
    "        .withColumn('porcentaje', round((col('count') / total) * 100,2))\\\n",
    "        .orderBy(colname).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de349a9-f1ad-437d-bd1f-c9a667d280d1",
   "metadata": {},
   "source": [
    "| Nombre Variable       | Dominio/Valores típicos             | Estadística comportamental                                       | Comentarios adicionales                                 |\n",
    "|-----------------------|-------------------------------------|------------------------------------------------------------------|---------------------------------------------------------|\n",
    "| **ID**                | 7,811,711 valores únicos            | min: 1, max: 7,811,711                                           | Identificador único, no aporta valor analítico          |\n",
    "| **Case Number**       | 7,811,707 valores únicos            | min: JB299184, max: ZZZ199957                                    | Identificador alfanumérico, uso administrativo          |\n",
    "| **Date**              | 01/01/2001 a 12/31/2022             | min: 01/01/2001 01:00 AM, max: 12/31/2022 12:59 PM               | Rango temporal del dataset                              |\n",
    "| **Block**             | Ejemplo: 0000X E 100 PL, XX UNKNOWN | —                                                                | Ubicación aproximada, puede tener valores ambiguos      |\n",
    "| **IUCR**              | min: 0110, max: 09901, únicos: 404  | media: 120.97, std: 466.18, moda: 0820 (632,836 veces)           | Código policial para tipo de crimen                     |\n",
    "| **Primary Type**      | Ej: ARSON, WEAPONS VIOLATION, #36   | Top: THEFT, moda: THEFT (1,647,915 veces)                        | Segmenta tipo de crimen; fundamental para análisis      |\n",
    "| **Description**       | Ej: $300 AND UNDER, únicos: 546      | Top: SIMPLE, moda: SIMPLE (916,750 veces)                        | Detalle específico del crimen                           |\n",
    "| **Location Desc.**    | Ej: \"CTA 'L' PLATFORM\", únicos: 216  | Top: STREET, moda: STREET (2,034,594 veces)                      | Contexto espacial/social                                |\n",
    "| **Arrest**            | True/False                          | True 26.08%, False 73.92%, moda: False (5,773,604 veces)         | Tasa de detenciones; analiza efectividad policial       |\n",
    "| **Domestic**          | True/False                          | True 13.8%, False 86.2%, moda: False (6,730,624 veces)           | Identifica delitos domésticos                           |\n",
    "| **Beat**              | min: 111, max: 2535, únicos: 305    | media: 1185.82, std: 1703.17, moda: 421 (60,858 veces)           | Unidad básica geográfica de patrullaje                  |\n",
    "| **District**          | min: 1, max: 31, únicos: 24         | media: 11.29, std: 6.95, moda: 8 (524,899 veces)                 | Zona administrativa policial                            |\n",
    "| **Ward**              | min: 1, max: 50, únicos: 50         | media: 22.75, std: 13.85, moda: NULL (614,848 veces)\\*           | División político-administrativa (muchos nulos)\\*       |\n",
    "| **Community Area**    | min: 1, max: 77, únicos: 78         | media: 37.48, std: 21.54, moda: NULL (613,476 veces)\\*           | Área oficial de Chicago (muchos nulos)\\*                |\n",
    "| **FBI Code**          | min: 01A, max: 26, únicos: 26       | media: 12.08, std: 7.31, moda: 06 (1,647,915 veces)              | Código estándar del FBI                                 |\n",
    "| **X Coordinate**      | min: 1025119, max: 1205159          | media: 1164603.29, std: 416840.03                                | Coordenada geográfica en sistema de Chicago             |\n",
    "| **Y Coordinate**      | min: 1622, max: 1951622             | media: 1885786.97, std: 889432.27                                | Coordenada geográfica en sistema de Chicago             |\n",
    "| **Year**              | 2001–2023                           | media: 2009.99, std: 6.29, moda: (completar)                     | Temporalidad del dato                                   |\n",
    "| **Updated On**        | 01/01/2007 07:32 AM a 12/31/2022... | —                                                                | Fecha de actualización                                  |\n",
    "| **Latitude**          | min: 36.62, max: 42.02              | media: 41.84, std: 0.09                                         | Coordenada geográfica                                   |\n",
    "| **Longitude**         | min: -91.69, max: -87.52            | media: -87.67, std: 0.06                                        | Coordenada geográfica                                   |\n",
    "| **Location**          | Ej: (36.6194…, -91.6865…)           | —                                                                | Combina latitud y longitud                              |\n",
    "\n",
    "\\* Muchos registros tienen valor nulo en Ward y Community Area.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e8e6e-0c98-48f0-b127-03e1e222b5e2",
   "metadata": {},
   "source": [
    "# Parte 2.\n",
    "## Selección de los datos:\n",
    "\n",
    "En esta etapa, el objetivo es trabajar con una muestra de tamaño manejable del dataset original, ya que procesar toda la base de datos sería muy costoso en tiempo y recursos. Para lograrlo, primero se definieron particiones relevantes usando las variables **“Primary Type”** y **“Domestic”**, que agrupan los registros según el tipo de crimen y si estuvo o no relacionado con violencia doméstica.\n",
    "\n",
    "En vez de analizar todos los datos posibles, se extrajeron únicamente los 5 tipos de delito más frecuentes y para cada uno se separaron las instancias en casos **domésticos** y **no domésticos**. Luego, para mantener un tamaño razonable pero representativo de cada grupo, se tomó una **muestra aleatoria del 10%** de cada partición, usando la misma técnica de muestreo propuesta en actividades anteriores.\n",
    "\n",
    "Finalmente, se unieron todas estas submuestras para formar una **muestra total** sobre la que se llevarán a cabo los análisis y modelos de *machine learning*, garantizando así que el conjunto de trabajo sea diverso, significativo y eficiente de procesar.\n",
    "\n",
    "Esta aproximación equilibra la necesidad de **velocidad y manejabilidad** con la de obtener **datos representativos** para todas las situaciones relevantes del fenómeno delictivo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "540d7293-72c1-41aa-a0da-e95a3be47f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: THEFT | Domestic: True | Total: 44739 | Muestra: 4391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: THEFT | Domestic: False | Total: 1603176 | Muestra: 160537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: BATTERY | Domestic: True | Total: 626184 | Muestra: 62739\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: BATTERY | Domestic: False | Total: 801552 | Muestra: 80409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: CRIMINAL DAMAGE | Domestic: True | Total: 76172 | Muestra: 7510\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: CRIMINAL DAMAGE | Domestic: False | Total: 814219 | Muestra: 81482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: NARCOTICS | Domestic: True | Total: 312 | Muestra: 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: NARCOTICS | Domestic: False | Total: 747849 | Muestra: 74833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: ASSAULT | Domestic: True | Total: 116731 | Muestra: 11674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primary Type: ASSAULT | Domestic: False | Total: 392983 | Muestra: 39349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 74:====================================================> (135 + 5) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tamaño total de la muestra final: 522964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Obtener los 5 tipos de crimen más frecuentes\n",
    "top_types = [row['Primary Type'] for row in df.groupBy('Primary Type').count()\n",
    "             .orderBy('count', ascending=False).limit(5).collect()]\n",
    "\n",
    "# Para cada tipo mas frecuente crear las particiones por 'Domestic' (True/False)\n",
    "muestras = []\n",
    "for t in top_types:\n",
    "    for domestic in [True, False]:\n",
    "        subgrupo = df.filter((col(\"Primary Type\") == t) & (col(\"Domestic\") == domestic))\n",
    "        # Se toma muestra del 10% de cada grupo, usando semilla fija para reproducibilidad\n",
    "        muestra = subgrupo.sample(fraction=0.1, seed=42)\n",
    "        muestras.append(muestra)\n",
    "        print(f\"Primary Type: {t} | Domestic: {domestic} | Total: {subgrupo.count()} | Muestra: {muestra.count()}\")\n",
    "\n",
    "# Unir todas las submuestras en un solo dataframe\n",
    "from functools import reduce\n",
    "from pyspark.sql import DataFrame\n",
    "muestra_total = reduce(DataFrame.unionAll, muestras)\n",
    "print(f\"\\nTamaño total de la muestra final: {muestra_total.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9958adb-4d11-4023-ba5b-ecb3f3e4a4d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>Arrest</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Ward</th>\n",
       "      <th>Community Area</th>\n",
       "      <th>FBI Code</th>\n",
       "      <th>X Coordinate</th>\n",
       "      <th>Y Coordinate</th>\n",
       "      <th>Year</th>\n",
       "      <th>Updated On</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10226106</td>\n",
       "      <td>HY413535</td>\n",
       "      <td>09/07/2015 03:00:00 AM</td>\n",
       "      <td>032XX N OCTAVIA AVE</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>17</td>\n",
       "      <td>06</td>\n",
       "      <td>1126857</td>\n",
       "      <td>1920644</td>\n",
       "      <td>2015</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.938579</td>\n",
       "      <td>-87.809186</td>\n",
       "      <td>(41.938578988, -87.809186242)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10228279</td>\n",
       "      <td>HY415980</td>\n",
       "      <td>09/08/2015 05:00:00 PM</td>\n",
       "      <td>053XX S CORNELL AVE</td>\n",
       "      <td>0810</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>OVER $500</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>41</td>\n",
       "      <td>06</td>\n",
       "      <td>1188157</td>\n",
       "      <td>1870260</td>\n",
       "      <td>2015</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.799074</td>\n",
       "      <td>-87.585509</td>\n",
       "      <td>(41.799073935, -87.585509129)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11859193</td>\n",
       "      <td>JC470832</td>\n",
       "      <td>10/13/2019 05:00:00 AM</td>\n",
       "      <td>076XX S ADA ST</td>\n",
       "      <td>0810</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>OVER $500</td>\n",
       "      <td>SIDEWALK</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>17</td>\n",
       "      <td>71</td>\n",
       "      <td>06</td>\n",
       "      <td>1168768</td>\n",
       "      <td>1853958</td>\n",
       "      <td>2019</td>\n",
       "      <td>10/20/2019 04:03:03 PM</td>\n",
       "      <td>41.754780</td>\n",
       "      <td>-87.657083</td>\n",
       "      <td>(41.754780109, -87.657082931)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10236438</td>\n",
       "      <td>HY424246</td>\n",
       "      <td>09/15/2015 11:20:00 AM</td>\n",
       "      <td>091XX S UNIVERSITY AVE</td>\n",
       "      <td>0810</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>OVER $500</td>\n",
       "      <td>STREET</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>06</td>\n",
       "      <td>1185476</td>\n",
       "      <td>1844552</td>\n",
       "      <td>2015</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.728592</td>\n",
       "      <td>-87.596149</td>\n",
       "      <td>(41.728592358, -87.59614881)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10238624</td>\n",
       "      <td>HY426363</td>\n",
       "      <td>09/16/2015 10:35:00 PM</td>\n",
       "      <td>049XX S FORRESTVILLE AVE</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>38</td>\n",
       "      <td>06</td>\n",
       "      <td>1180761</td>\n",
       "      <td>1872355</td>\n",
       "      <td>2015</td>\n",
       "      <td>02/10/2018 03:50:01 PM</td>\n",
       "      <td>41.804996</td>\n",
       "      <td>-87.612567</td>\n",
       "      <td>(41.804996159, -87.612567255)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Case Number                    Date                     Block  \\\n",
       "0  10226106    HY413535  09/07/2015 03:00:00 AM       032XX N OCTAVIA AVE   \n",
       "1  10228279    HY415980  09/08/2015 05:00:00 PM       053XX S CORNELL AVE   \n",
       "2  11859193    JC470832  10/13/2019 05:00:00 AM            076XX S ADA ST   \n",
       "3  10236438    HY424246  09/15/2015 11:20:00 AM    091XX S UNIVERSITY AVE   \n",
       "4  10238624    HY426363  09/16/2015 10:35:00 PM  049XX S FORRESTVILLE AVE   \n",
       "\n",
       "   IUCR Primary Type     Description Location Description  Arrest  Domestic  \\\n",
       "0  0820        THEFT  $500 AND UNDER            RESIDENCE   False      True   \n",
       "1  0810        THEFT       OVER $500            RESIDENCE   False      True   \n",
       "2  0810        THEFT       OVER $500             SIDEWALK   False      True   \n",
       "3  0810        THEFT       OVER $500               STREET    True      True   \n",
       "4  0820        THEFT  $500 AND UNDER            APARTMENT   False      True   \n",
       "\n",
       "   ...  Ward  Community Area  FBI Code  X Coordinate Y Coordinate  Year  \\\n",
       "0  ...    36              17        06       1126857      1920644  2015   \n",
       "1  ...     5              41        06       1188157      1870260  2015   \n",
       "2  ...    17              71        06       1168768      1853958  2019   \n",
       "3  ...     8              47        06       1185476      1844552  2015   \n",
       "4  ...     4              38        06       1180761      1872355  2015   \n",
       "\n",
       "               Updated On   Latitude  Longitude                       Location  \n",
       "0  02/10/2018 03:50:01 PM  41.938579 -87.809186  (41.938578988, -87.809186242)  \n",
       "1  02/10/2018 03:50:01 PM  41.799074 -87.585509  (41.799073935, -87.585509129)  \n",
       "2  10/20/2019 04:03:03 PM  41.754780 -87.657083  (41.754780109, -87.657082931)  \n",
       "3  02/10/2018 03:50:01 PM  41.728592 -87.596149   (41.728592358, -87.59614881)  \n",
       "4  02/10/2018 03:50:01 PM  41.804996 -87.612567  (41.804996159, -87.612567255)  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "muestra_total.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef0ca37-1841-4031-92e3-cb98caf35cbb",
   "metadata": {},
   "source": [
    "## Parte 3: Selección de columnas clave\n",
    "\n",
    "Se seleccionaron las columnas más importantes para hacer un **análisis general** de los delitos. La idea en esta etapa no es entrar en temas muy específicos, es solo tener una vista amplia del comportamiento delictivo.\n",
    "Las columnas seleccionadas fueron:\n",
    "\n",
    "- **Primary Type**: Indica el tipo de crimen. Es la base para clasificar los delitos y entender qué tipos son más frecuentes.\n",
    "- **Domestic**: Muestra si el delito estuvo relacionado con violencia doméstica. Esto permite separar casos con una dinámica social distinta.\n",
    "- **Arrest**: Informa si hubo o no una detención. Nos ayuda a analizar la respuesta de las autoridades ante diferentes tipos de crímenes.\n",
    "- **Date**: Registra la fecha exacta del crimen. Sirve para hacer análisis temporales, identificar patrones por día, mes o incluso por horarios.\n",
    "- **Location Description**: Describe el tipo de lugar donde ocurrió el delito (por ejemplo, calle, casa, escuela). Esto aporta un contexto espacial muy valioso.\n",
    "- **Year**: Permite agrupar los casos por año y ver cómo han cambiado los patrones delictivos con el tiempo.\n",
    "\n",
    "Estas columnas fueron elegidas porque ofrecen una base sólida para hacer un análisis amplio y útil, sin complicar demasiado los datos. Nos dan información suficiente para detectar tendencias, comparar situaciones y empezar a responder preguntas clave sobre el fenómeno delictivo en general.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd328123-465c-4487-9f24-ac22c1f82d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'Primary Type': 0 valores nulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'Domestic': 0 valores nulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'Arrest': 0 valores nulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'Date': 0 valores nulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'Year': 0 valores nulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columna 'Location Description': 86 valores nulos\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Registros antes de eliminar nulos: 522964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 101:==================================================>  (133 + 7) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de eliminar nulos: 522878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Revisar rangos de año y fecha\n",
    "muestra_final.select(\"Year\").describe().show()\n",
    "muestra_final.agg({\"Year\": \"min\", \"Year\": \"max\"}).show()\n",
    "muestra_final.agg({\"Date_ts\": \"min\", \"Date_ts\": \"max\"}).show()\n",
    "# Verificaremos los valores nulos por columna clave\n",
    "for columna in columnas_clave:\n",
    "    n_nulos = muestra_total.filter(col(columna).isNull()).count()\n",
    "    print(f\"Columna '{columna}': {n_nulos} valores nulos\")\n",
    "\n",
    "# Elimina las filas con al menos un nulo en las columnas clave seleccionadas\n",
    "muestra_total_sin_nulos = muestra_total.dropna(subset=columnas_clave)\n",
    "\n",
    "print(f\"\\nRegistros antes de eliminar nulos: {muestra_total.count()}\")\n",
    "print(f\"Registros después de eliminar nulos: {muestra_total_sin_nulos.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c712194f-5c97-4e6f-9204-8f4b28306857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Case Number: string (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Block: string (nullable = true)\n",
      " |-- IUCR: string (nullable = true)\n",
      " |-- Primary Type: string (nullable = true)\n",
      " |-- Description: string (nullable = true)\n",
      " |-- Location Description: string (nullable = true)\n",
      " |-- Arrest: boolean (nullable = true)\n",
      " |-- Domestic: boolean (nullable = true)\n",
      " |-- Beat: integer (nullable = true)\n",
      " |-- District: integer (nullable = true)\n",
      " |-- Ward: integer (nullable = true)\n",
      " |-- Community Area: integer (nullable = true)\n",
      " |-- FBI Code: string (nullable = true)\n",
      " |-- X Coordinate: integer (nullable = true)\n",
      " |-- Y Coordinate: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Updated On: string (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "muestra_total_sin_nulos.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5689d694-7d4e-4c00-96ae-26ee68c6a5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-------------------+\n",
      "|Date                  |Date_ts            |\n",
      "+----------------------+-------------------+\n",
      "|09/07/2015 03:00:00 AM|2015-09-07 03:00:00|\n",
      "|09/08/2015 05:00:00 PM|2015-09-08 17:00:00|\n",
      "|10/13/2019 05:00:00 AM|2019-10-13 05:00:00|\n",
      "+----------------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_timestamp\n",
    "\n",
    "# Convierte columna 'Date' a tipo timestamp (creará nueva columna 'Date_ts')\n",
    "muestra_final = muestra_total_sin_nulos.withColumn(\n",
    "    \"Date_ts\",\n",
    "    to_timestamp(\"Date\", \"MM/dd/yyyy hh:mm:ss a\")\n",
    ")\n",
    "\n",
    "# Opcional: elimina la columna original si solo quieres la nueva\n",
    "# muestra_final = muestra_final.drop(\"Date\").withColumnRenamed(\"Date_ts\", \"Date\")\n",
    "\n",
    "# Checa el resultado:\n",
    "muestra_final.select(\"Date\", \"Date_ts\").show(3, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3edb4e7-6e00-4afa-b1cc-0388dcad3eaa",
   "metadata": {},
   "source": [
    "## Corrección de formatos y tipos de datos\n",
    "\n",
    "La revisión de los tipos de datos en las columnas clave mostró que la mayoría estaban en un formato adecuado, salvo la columna **`Date`**, que se encontraba como tipo *string*. Esta columna fue convertida al tipo **fecha-hora (`timestamp`)** usando la función to_timestamp de PySpark, permitiendo así futuros análisis temporales y segmentaciones por mes, día, hora, etc.\n",
    "\n",
    "El resto de las variables principales ya parecen estar con el tipo correcto.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "859fa479-83b3-4a43-9693-3766744f98ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              Year|\n",
      "+-------+------------------+\n",
      "|  count|            522878|\n",
      "|   mean| 2009.869242920911|\n",
      "| stddev|6.2519741986148825|\n",
      "|    min|              2001|\n",
      "|    max|              2023|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|max(Year)|\n",
      "+---------+\n",
      "|     2023|\n",
      "+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 111:===================================================> (136 + 4) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|       max(Date_ts)|\n",
      "+-------------------+\n",
      "|2023-05-29 22:00:00|\n",
      "+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Revisar rangos de año y fecha\n",
    "muestra_final.select(\"Year\").describe().show()\n",
    "muestra_final.agg({\"Year\": \"min\", \"Year\": \"max\"}).show()\n",
    "muestra_final.agg({\"Date_ts\": \"min\", \"Date_ts\": \"max\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cb0619e-cf65-47df-bd09-75fa0d9bf47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-------------------+\n",
      "|summary|           Latitude|          Longitude|\n",
      "+-------+-------------------+-------------------+\n",
      "|  count|             518172|             518172|\n",
      "|   mean| 41.842532236626866| -87.67135204858764|\n",
      "| stddev|0.08889303854151867|0.06112646809451275|\n",
      "|    min|       36.619446395|      -91.686565684|\n",
      "|    max|         42.0226409|      -87.524529378|\n",
      "+-------+-------------------+-------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 117:===================================================> (137 + 3) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+\n",
      "|max(Latitude)|max(Longitude)|\n",
      "+-------------+--------------+\n",
      "|   42.0226409| -87.524529378|\n",
      "+-------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "muestra_final.select(\"Latitude\", \"Longitude\").describe().show()\n",
    "muestra_final.agg(\n",
    "    {\"Latitude\": \"min\", \"Latitude\": \"max\", \"Longitude\": \"min\", \"Longitude\": \"max\"}\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45daffd5-0db0-4666-b18d-f15d55577f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros antes de filtrar: 522878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 123:===================================================> (136 + 4) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros después de filtrar ubicaciones fuera de rango: 518162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Filtramos registros con latitud y longitud dentro de Chicago\n",
    "muestra_final_limpia = muestra_final.filter(\n",
    "    ((col('Latitude') >= 41.6) & (col('Latitude') <= 42.1)) &\n",
    "    ((col('Longitude') >= -88) & (col('Longitude') <= -87.5))\n",
    ")\n",
    "\n",
    "print('Registros antes de filtrar:', muestra_final.count())\n",
    "print('Registros después de filtrar ubicaciones fuera de rango:', muestra_final_limpia.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ad6dfde-52c5-4b7f-af8c-b08c33f7e31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------------+--------------------+------------------+\n",
      "|Primary Type|PrimaryType_index|Location Description|LocationDesc_index|\n",
      "+------------+-----------------+--------------------+------------------+\n",
      "|       THEFT|              0.0|           RESIDENCE|               1.0|\n",
      "|       THEFT|              0.0|           RESIDENCE|               1.0|\n",
      "|       THEFT|              0.0|            SIDEWALK|               3.0|\n",
      "|       THEFT|              0.0|              STREET|               0.0|\n",
      "|       THEFT|              0.0|           APARTMENT|               2.0|\n",
      "+------------+-----------------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "# Indexar Primary Type y Location Description\n",
    "indexer_pt = StringIndexer(inputCol=\"Primary Type\", outputCol=\"PrimaryType_index\")\n",
    "indexer_ld = StringIndexer(inputCol=\"Location Description\", outputCol=\"LocationDesc_index\")\n",
    "\n",
    "muestra_indexeada = indexer_pt.fit(muestra_final).transform(muestra_final)\n",
    "muestra_indexeada = indexer_ld.fit(muestra_indexeada).transform(muestra_indexeada)\n",
    "\n",
    "muestra_indexeada.select(\"Primary Type\", \"PrimaryType_index\", \"Location Description\", \"LocationDesc_index\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96d37bef-e4f6-4e57-bec5-be2527ff6ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----+---------+----+\n",
      "|            Date_ts|Month|DayOfWeek|Hour|\n",
      "+-------------------+-----+---------+----+\n",
      "|2015-09-07 03:00:00|    9|        2|   3|\n",
      "|2015-09-08 17:00:00|    9|        3|  17|\n",
      "|2019-10-13 05:00:00|   10|        1|   5|\n",
      "|2015-09-15 11:20:00|    9|        3|  11|\n",
      "|2015-09-16 22:35:00|    9|        4|  22|\n",
      "+-------------------+-----+---------+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month, dayofweek, hour\n",
    "\n",
    "# Creamos nuevas columnas de mes, día de la semana y hora\n",
    "muestra_ext = muestra_indexeada \\\n",
    "    .withColumn(\"Month\", month(\"Date_ts\")) \\\n",
    "    .withColumn(\"DayOfWeek\", dayofweek(\"Date_ts\")) \\\n",
    "    .withColumn(\"Hour\", hour(\"Date_ts\"))\n",
    "\n",
    "# Visualizamos un par de filas para ver las nuevas columnas\n",
    "muestra_ext.select(\"Date_ts\", \"Month\", \"DayOfWeek\", \"Hour\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976be850-152c-475a-b615-2b258e4a9c67",
   "metadata": {},
   "source": [
    "## Transformación de variables temporales\n",
    "\n",
    "A partir de la columna de fecha-hora (**`Date_ts`**), se generaron tres nuevas variables que permiten analizar con mayor detalle los patrones temporales de los delitos:\n",
    "\n",
    "- **`Month`**: Número del mes en que ocurrió el crimen (valores de 1 a 12).\n",
    "- **`DayOfWeek`**: Día de la semana en que ocurrió el crimen (1 = domingo, 7 = sábado, siguiendo el formato estándar de PySpark).\n",
    "- **`Hour`**: Hora del día en que ocurrió el crimen (valores de 0 a 23).\n",
    "\n",
    "Estas variables son útiles para detectar **patrones estacionales**, identificar **días con mayor incidencia delictiva**, y analizar las **franjas horarias con más actividad criminal**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01516979-fea9-4aea-b38c-58228723e53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------------+--------+------+----+-----+---------+----+-------------------------------------+\n",
      "|PrimaryType_index|LocationDesc_index|Domestic|Arrest|Year|Month|DayOfWeek|Hour|features                             |\n",
      "+-----------------+------------------+--------+------+----+-----+---------+----+-------------------------------------+\n",
      "|0.0              |1.0               |true    |false |2015|9    |2        |3   |[0.0,1.0,1.0,0.0,2015.0,9.0,2.0,3.0] |\n",
      "|0.0              |1.0               |true    |false |2015|9    |3        |17  |[0.0,1.0,1.0,0.0,2015.0,9.0,3.0,17.0]|\n",
      "|0.0              |3.0               |true    |false |2019|10   |1        |5   |[0.0,3.0,1.0,0.0,2019.0,10.0,1.0,5.0]|\n",
      "|0.0              |0.0               |true    |true  |2015|9    |3        |11  |[0.0,0.0,1.0,1.0,2015.0,9.0,3.0,11.0]|\n",
      "|0.0              |2.0               |true    |false |2015|9    |4        |22  |[0.0,2.0,1.0,0.0,2015.0,9.0,4.0,22.0]|\n",
      "+-----------------+------------------+--------+------+----+-----+---------+----+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Definimos las columnas de entrada para el modelo\n",
    "columnas_features = [\n",
    "    \"PrimaryType_index\",\n",
    "    \"LocationDesc_index\",\n",
    "    \"Domestic\",\n",
    "    \"Arrest\",\n",
    "    \"Year\",\n",
    "    \"Month\",\n",
    "    \"DayOfWeek\",\n",
    "    \"Hour\"\n",
    "]\n",
    "\n",
    "# Construimos el ensamblador de vector\n",
    "assembler = VectorAssembler(inputCols=columnas_features, outputCol=\"features\")\n",
    "\n",
    "# Transformamos el dataframe\n",
    "muestra_features = assembler.transform(muestra_ext)\n",
    "\n",
    "# Visualizamos ejemplo de features\n",
    "muestra_features.select(columnas_features + ['features']).show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad7912-d20e-43ef-971e-cfc5458a2f91",
   "metadata": {},
   "source": [
    "## Preparación del vector de características (\"features\")\n",
    "\n",
    "Para poder aplicar los modelos de aprendizaje automático en PySpark, fue necesario **convertir todas las variables relevantes a un único vector numérico**, ya que este es el formato requerido por los algoritmos.\n",
    "\n",
    "Las variables utilizadas fueron:\n",
    "\n",
    "- **`PrimaryType_index`**: Índice numérico que representa el tipo de crimen.\n",
    "- **`LocationDesc_index`**: Índice numérico para el lugar donde ocurrió el crimen.\n",
    "- **`Domestic`** y **`Arrest`**: Variables booleanas (valores `True` o `False`).\n",
    "- **`Year`**, **`Month`**, **`DayOfWeek`**, **`Hour`**: Variables temporales representadas numéricamente.\n",
    "\n",
    "Todas estas variables fueron **ensambladas en una sola columna llamada `features`** utilizando la función `VectorAssembler` de PySpark, lo que permite alimentar correctamente los modelos de machine learning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce3c8a0-db51-4bba-9931-e260af12446a",
   "metadata": {},
   "source": [
    "## Parte 4: Preparación del conjunto de entrenamiento y prueba\n",
    "\n",
    "En esta etapa, el objetivo fue dividir la muestra **M** ya preprocesada en dos subconjuntos: uno para **entrenar los modelos** y otro para **evaluar su rendimiento** de forma objetiva.\n",
    "\n",
    "Para minimizar el riesgo de sesgo y mantener la representatividad de los datos, se utilizó una técnica de **muestreo aleatorio simple**. Esta técnica garantiza que cada registro tenga la misma probabilidad de ser asignado a cualquiera de los dos conjuntos, evitando así una distribución sesgada.\n",
    "\n",
    "La división se hizo en proporción **70% para entrenamiento y 30% para prueba**. Esta elección permite contar con una base sólida para entrenar los modelos, sin dejar de lado un conjunto suficiente para realizar una evaluación confiable y replicable del desempeño del modelo.\n",
    "\n",
    "Esta preparación es clave para garantizar que los resultados obtenidos en la etapa de modelado sean válidos y generalizables a nuevos datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5520bf2e-e7fb-4e0b-a683-fa7a07f68670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en conjunto de entrenamiento: 365684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 138:===================================================> (135 + 5) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en conjunto de prueba: 157194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "entrenamiento, prueba = muestra_features.randomSplit([0.7, 0.3], seed=42)\n",
    "\n",
    "print(\"Registros en conjunto de entrenamiento:\", entrenamiento.count())\n",
    "print(\"Registros en conjunto de prueba:\", prueba.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "519a7442-09d6-48fc-9831-87ab65ac0693",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrenamiento = entrenamiento.withColumnRenamed('Arrest', 'label')\n",
    "prueba = prueba.withColumnRenamed('Arrest', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "051e1647-bcab-4466-8b49-860c234b6d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,0.0,1.0,0.0,...|false|\n",
      "|[0.0,1.0,1.0,0.0,...|false|\n",
      "|[0.0,2.0,1.0,0.0,...|false|\n",
      "|[0.0,0.0,1.0,0.0,...|false|\n",
      "|[0.0,0.0,1.0,0.0,...|false|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------+-----+\n",
      "|            features|label|\n",
      "+--------------------+-----+\n",
      "|[0.0,5.0,1.0,0.0,...|false|\n",
      "|[0.0,1.0,1.0,0.0,...|false|\n",
      "|[0.0,2.0,1.0,0.0,...|false|\n",
      "|[0.0,1.0,1.0,0.0,...|false|\n",
      "|[0.0,14.0,1.0,0.0...|false|\n",
      "+--------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "entrenamiento.select(\"features\", \"label\").show(5)\n",
    "prueba.select(\"features\", \"label\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "35bc6477-f23e-4647-b296-949f745539ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Para entrenamiento:\n",
    "entrenamiento = entrenamiento.withColumn(\"label\", col(\"label\").cast(\"int\"))\n",
    "\n",
    "# Para prueba:\n",
    "prueba = prueba.withColumn(\"label\", col(\"label\").cast(\"int\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b6d5ac0-83c7-431a-a469-5f1f5f909889",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Case Number</th>\n",
       "      <th>Date</th>\n",
       "      <th>Block</th>\n",
       "      <th>IUCR</th>\n",
       "      <th>Primary Type</th>\n",
       "      <th>Description</th>\n",
       "      <th>Location Description</th>\n",
       "      <th>label</th>\n",
       "      <th>Domestic</th>\n",
       "      <th>...</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Location</th>\n",
       "      <th>Date_ts</th>\n",
       "      <th>PrimaryType_index</th>\n",
       "      <th>LocationDesc_index</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Hour</th>\n",
       "      <th>features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000299</td>\n",
       "      <td>HY189997</td>\n",
       "      <td>03/18/2015 09:15:00 PM</td>\n",
       "      <td>111XX S SANGAMON ST</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>41.691859</td>\n",
       "      <td>-87.646011</td>\n",
       "      <td>(41.691858549, -87.646011379)</td>\n",
       "      <td>2015-03-18 21:15:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2015.0, 3.0, 4.0, 21.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10045903</td>\n",
       "      <td>HY234588</td>\n",
       "      <td>04/23/2015 02:00:00 PM</td>\n",
       "      <td>023XX S ST LOUIS AVE</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>RESIDENCE</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>41.849021</td>\n",
       "      <td>-87.712482</td>\n",
       "      <td>(41.849021464, -87.712481981)</td>\n",
       "      <td>2015-04-23 14:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>[0.0, 1.0, 1.0, 0.0, 2015.0, 4.0, 5.0, 14.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10090145</td>\n",
       "      <td>HY278040</td>\n",
       "      <td>05/26/2015 06:00:00 AM</td>\n",
       "      <td>060XX S HARPER AVE</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>APARTMENT</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>41.784755</td>\n",
       "      <td>-87.588143</td>\n",
       "      <td>(41.784754925, -87.588143196)</td>\n",
       "      <td>2015-05-26 06:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>[0.0, 2.0, 1.0, 0.0, 2015.0, 5.0, 3.0, 6.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10152897</td>\n",
       "      <td>HY338204</td>\n",
       "      <td>07/12/2015 09:00:00 PM</td>\n",
       "      <td>0000X N HAMLIN BLVD</td>\n",
       "      <td>0820</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>$500 AND UNDER</td>\n",
       "      <td>STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>41.881089</td>\n",
       "      <td>-87.720764</td>\n",
       "      <td>(41.881088655, -87.720764494)</td>\n",
       "      <td>2015-07-12 21:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2015.0, 7.0, 1.0, 21.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10159232</td>\n",
       "      <td>HY348537</td>\n",
       "      <td>07/20/2015 04:30:00 PM</td>\n",
       "      <td>067XX S MORGAN ST</td>\n",
       "      <td>0810</td>\n",
       "      <td>THEFT</td>\n",
       "      <td>OVER $500</td>\n",
       "      <td>STREET</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>...</td>\n",
       "      <td>41.771670</td>\n",
       "      <td>-87.649434</td>\n",
       "      <td>(41.771669908, -87.649434458)</td>\n",
       "      <td>2015-07-20 16:30:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>[0.0, 0.0, 1.0, 0.0, 2015.0, 7.0, 2.0, 16.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID Case Number                    Date                 Block  IUCR  \\\n",
       "0  10000299    HY189997  03/18/2015 09:15:00 PM   111XX S SANGAMON ST  0820   \n",
       "1  10045903    HY234588  04/23/2015 02:00:00 PM  023XX S ST LOUIS AVE  0820   \n",
       "2  10090145    HY278040  05/26/2015 06:00:00 AM    060XX S HARPER AVE  0820   \n",
       "3  10152897    HY338204  07/12/2015 09:00:00 PM   0000X N HAMLIN BLVD  0820   \n",
       "4  10159232    HY348537  07/20/2015 04:30:00 PM     067XX S MORGAN ST  0810   \n",
       "\n",
       "  Primary Type     Description Location Description  label  Domestic  ...  \\\n",
       "0        THEFT  $500 AND UNDER               STREET      0      True  ...   \n",
       "1        THEFT  $500 AND UNDER            RESIDENCE      0      True  ...   \n",
       "2        THEFT  $500 AND UNDER            APARTMENT      0      True  ...   \n",
       "3        THEFT  $500 AND UNDER               STREET      0      True  ...   \n",
       "4        THEFT       OVER $500               STREET      0      True  ...   \n",
       "\n",
       "    Latitude  Longitude                       Location             Date_ts  \\\n",
       "0  41.691859 -87.646011  (41.691858549, -87.646011379) 2015-03-18 21:15:00   \n",
       "1  41.849021 -87.712482  (41.849021464, -87.712481981) 2015-04-23 14:00:00   \n",
       "2  41.784755 -87.588143  (41.784754925, -87.588143196) 2015-05-26 06:00:00   \n",
       "3  41.881089 -87.720764  (41.881088655, -87.720764494) 2015-07-12 21:00:00   \n",
       "4  41.771670 -87.649434  (41.771669908, -87.649434458) 2015-07-20 16:30:00   \n",
       "\n",
       "  PrimaryType_index  LocationDesc_index  Month  DayOfWeek Hour  \\\n",
       "0               0.0                 0.0      3          4   21   \n",
       "1               0.0                 1.0      4          5   14   \n",
       "2               0.0                 2.0      5          3    6   \n",
       "3               0.0                 0.0      7          1   21   \n",
       "4               0.0                 0.0      7          2   16   \n",
       "\n",
       "                                       features  \n",
       "0  [0.0, 0.0, 1.0, 0.0, 2015.0, 3.0, 4.0, 21.0]  \n",
       "1  [0.0, 1.0, 1.0, 0.0, 2015.0, 4.0, 5.0, 14.0]  \n",
       "2   [0.0, 2.0, 1.0, 0.0, 2015.0, 5.0, 3.0, 6.0]  \n",
       "3  [0.0, 0.0, 1.0, 0.0, 2015.0, 7.0, 1.0, 21.0]  \n",
       "4  [0.0, 0.0, 1.0, 0.0, 2015.0, 7.0, 2.0, 16.0]  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entrenamiento.limit(5).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30e39ab-5c17-4f73-afae-769e4f4015dd",
   "metadata": {},
   "source": [
    "## Parte 5\n",
    "\n",
    "# Aprendizaje Supervisado: Entrenamiento y Evaluación del Modelo\n",
    "\n",
    "En la siguiente etapa, se entrenará un modelo de árbol de decisión utilizando el **DecisionTreeClassifier** de PySpark. El objetivo será predecir la probabilidad de arresto a partir de las variables seleccionadas y previamente procesadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "26e0c946-1f46-4376-85c8-1e44a01b6b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC (Area Under ROC) del modelo de Árbol de Decisión: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 171:>                                                        (0 + 1) / 1]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+-----+--------------+-----------+----------+\n",
      "|features                              |label|rawPrediction |probability|prediction|\n",
      "+--------------------------------------+-----+--------------+-----------+----------+\n",
      "|[0.0,5.0,1.0,0.0,2015.0,5.0,4.0,14.0] |0    |[267306.0,0.0]|[1.0,0.0]  |0.0       |\n",
      "|[0.0,1.0,1.0,0.0,2015.0,7.0,1.0,20.0] |0    |[267306.0,0.0]|[1.0,0.0]  |0.0       |\n",
      "|[0.0,2.0,1.0,0.0,2015.0,7.0,5.0,0.0]  |0    |[267306.0,0.0]|[1.0,0.0]  |0.0       |\n",
      "|[0.0,1.0,1.0,0.0,2015.0,7.0,2.0,22.0] |0    |[267306.0,0.0]|[1.0,0.0]  |0.0       |\n",
      "|[0.0,14.0,1.0,0.0,2015.0,8.0,5.0,13.0]|0    |[267306.0,0.0]|[1.0,0.0]  |0.0       |\n",
      "+--------------------------------------+-----+--------------+-----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "# Crea el clasificador\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxBins=200, seed=42)\n",
    "\n",
    "# Entrena el modelo con el conjunto de entrenamiento\n",
    "modelo_dt = dt.fit(entrenamiento)\n",
    "\n",
    "# Genera predicciones\n",
    "predicciones = modelo_dt.transform(prueba)\n",
    "\n",
    "# Recomendado usar AUC para problemas binarios\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "auc = evaluator.evaluate(predicciones)\n",
    "\n",
    "print(\"AUC (Area Under ROC) del modelo de Árbol de Decisión:\", auc)\n",
    "\n",
    "predicciones.select(\"features\", \"label\", \"rawPrediction\", \"probability\", \"prediction\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d872f3da-528c-46fa-ab30-0d4b9477e6e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1| 42332|\n",
      "|    0|114862|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 175:===================================================> (135 + 5) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+\n",
      "|label| count|\n",
      "+-----+------+\n",
      "|    1| 98378|\n",
      "|    0|267306|\n",
      "+-----+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Cuántos 0 y 1 hay en el conjunto de prueba\n",
    "prueba.groupBy(\"label\").count().show()\n",
    "# En entrenamiento\n",
    "entrenamiento.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f8233-363c-42d6-a3db-d5df6009add1",
   "metadata": {},
   "source": [
    "## Resultados del modelo\n",
    "\n",
    "El árbol de decisión tuvo un AUC de 1.0, lo cual puede sonar muy bueno, pero en este caso no significa necesariamente que el modelo esté funcionando bien. Al revisar las etiquetas de la variable objetivo (label), se notó que solo alrededor del 27% de los registros correspondían a casos con arresto (valor \"1\"), mientras que la mayoría (73%) eran sin arresto (valor \"0\").\n",
    "\n",
    "Esto indica que el modelo probablemente está aprendiendo a predecir siempre la clase más común, lo que hace que pierda capacidad para distinguir entre casos con y sin arresto.\n",
    "\n",
    "Este resultado muestra lo importante que es revisar el balance entre clases cuando se trabaja con clasificación. En situaciones como esta, sería recomendable usar técnicas como el submuestreo de la clase mayoritaria, el sobremuestreo de la minoritaria o métricas como balanced accuracy o F1-score que se ajustan mejor a datos desbalanceados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03092cb1-7df9-44d0-bcad-ba2cfbe13c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 193:==================================================>  (134 + 6) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC balanceado: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Balanceando usando undersampling\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Filtra positivos y negativos\n",
    "positivos = entrenamiento.filter(col(\"label\") == 1)\n",
    "negativos = entrenamiento.filter(col(\"label\") == 0)\n",
    "\n",
    "# Toma la misma cantidad de negativos que positivos\n",
    "negativos_sampled = negativos.sample(fraction=positivos.count() / negativos.count(), seed=42)\n",
    "\n",
    "# Junta ambos\n",
    "entrenamiento_balanceado = positivos.union(negativos_sampled)\n",
    "\n",
    "# Ajusta el árbol de decisión ahora con este set\n",
    "dt = DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features\", maxBins=200, seed=42)\n",
    "modelo_dt_balanceado = dt.fit(entrenamiento_balanceado)\n",
    "predicciones_balanceado = modelo_dt_balanceado.transform(prueba)\n",
    "auc_balanceado = evaluator.evaluate(predicciones_balanceado)\n",
    "print(\"AUC balanceado:\", auc_balanceado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b87cf934-ee96-4dff-9490-076d1c0f3f07",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 204:===================================================> (136 + 4) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+----------+------+\n",
      "|label|prediction| count|\n",
      "+-----+----------+------+\n",
      "|    0|       0.0|114862|\n",
      "|    1|       1.0| 42332|\n",
      "+-----+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "confusion = predicciones.groupBy(\"label\", \"prediction\").count().orderBy(\"label\", \"prediction\")\n",
    "confusion.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76b1dbc2-b819-4291-a8b8-d0b71a72d2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 213:===================================================> (137 + 3) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|       0.0|114862|\n",
      "|       1.0| 42332|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "predicciones.groupBy(\"prediction\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "69430c53-fd85-4ac3-a557-0bae5e8b3f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 216:===================================================> (137 + 3) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Área bajo la curva ROC: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"label\", rawPredictionCol=\"rawPrediction\", metricName=\"areaUnderROC\")\n",
    "roc_auc = evaluator.evaluate(predicciones)\n",
    "print(f\"Área bajo la curva ROC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6a1c61-0613-4731-a297-5dee9f2f6299",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "\n",
    "El modelo de árbol de decisión que entrené dio resultados perfectos: logró clasificar correctamente todos los registros del conjunto de prueba y la métrica AUC fue de 1.0 (el valor más alto posible). A simple vista, esto podría sonar ideal, pero la verdad es que es muy raro que un modelo sea tan preciso en la vida real.\n",
    "\n",
    "Cuando pasa algo así, lo más común es que hay algún detalle en los datos o en la preparación que está ayudando demasiado al modelo. Puede ser que los datos de entrenamiento y prueba no estén realmente bien mezclados, que las variables predictoras sean tan informativas que prácticamente le dan la solución al modelo, o que todavía exista cierto desbalance de clases que está influyendo en el resultado.\n",
    "\n",
    "Aunque los números sean excelentes, es importante no confiarse y analizar con cuidado todo el flujo del preprocesamiento y la partición de los datos. Antes de usar este modelo para tomar decisiones importantes, mejor hacer una validación más profunda, probar otras métricas, nuevas particiones o incluso técnicas adicionales de balanceo y revisión de features.\n",
    "\n",
    "El modelo funcionó \"demasiado bien\", pero eso es precisamente una señal para ser críticos y seguir cuestionando los resultados antes de sacar conclusiones definitivas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a48c166-6ce0-4322-bc68-49cc0e94c793",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en conjunto de entrenamiento: 365684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 230:==================================================>  (134 + 6) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros en conjunto de prueba: 157194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "print(\"Registros en conjunto de entrenamiento:\", entrenamiento.count())\n",
    "print(\"Registros en conjunto de prueba:\", prueba.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41c30d6-2c61-4d4e-b01a-61addb5097f6",
   "metadata": {},
   "source": [
    "### Aprendizaje No Supervisado: Agrupamiento con K-Means\n",
    "\n",
    "Se aplicará el algoritmo K-Means con PySpark para realizar un agrupamiento no supervisado sobre la muestra preprocesada. El objetivo es encontrar posibles patrones ocultos y segmentar los datos en grupos que compartan características similares, utilizando el vector de características, generado en los pasos anteriores. Se establecerá el parámetro `k` como 4 para comenzar el análisis, aunque este valor podría ajustarse según los resultados obtenidos. Se evaluará la calidad de los clusters utilizando el coeficiente Silhouette y se explorarán los perfiles típicos de cada grupo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f68dd07a-6048-40e5-8834-2ff71c6254ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/05/25 12:55:14 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente Silhouette para K-means: 0.3899740206596606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 292:=================================================>   (132 + 8) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------+\n",
      "|prediction| count|\n",
      "+----------+------+\n",
      "|         1| 89001|\n",
      "|         3|102115|\n",
      "|         2| 29152|\n",
      "|         0|145416|\n",
      "+----------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.evaluation import ClusteringEvaluator\n",
    "\n",
    "muestra_completa = entrenamiento.union(prueba)\n",
    "\n",
    "kmeans = KMeans(featuresCol=\"features\", k=4, seed=42)\n",
    "modelo_kmeans = kmeans.fit(muestra_completa)\n",
    "\n",
    "clusters = modelo_kmeans.transform(entrenamiento)\n",
    "\n",
    "evaluator = ClusteringEvaluator(featuresCol=\"features\", metricName='silhouette', distanceMeasure='squaredEuclidean')\n",
    "silhouette = evaluator.evaluate(clusters)\n",
    "print(\"Coeficiente Silhouette para K-means:\", silhouette)\n",
    "\n",
    "clusters.groupBy(\"prediction\").count().show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7271478-8c67-430d-99cf-95727ea2b951",
   "metadata": {},
   "source": [
    "### Resultados del Agrupamiento con K-Means\n",
    "\n",
    "Después de entrenar el modelo K-Means con `k=4`, se evaluó la calidad de los clusters utilizando el coeficiente Silhouette, obteniendo un valor de **0.39**. Indica que los clusters formados presentan una separación aceptable, aunque no perfecta. Un silhouette mayor de 0.5 indicaría clusters muy bien definidos; en este caso, el resultado sugiere que los grupos existen, pero podrían solaparse un poco en las fronteras.\n",
    "\n",
    "Esto muestra que algunos clusters son mucho más grandes que otros, lo cual es común cuando se usa K-Means con datos reales.\n",
    "\n",
    "El uso de K-Means permitió segmentar el dataset en subgrupos que comparten ciertos rasgos similares, es útil para análisis exploratorios y para descubrir perfiles o tendencias dentro de la base de datos de crímenes de Chicago."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2ea35b4f-c7e0-4fa1-b0cb-a65debde2ea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centro del cluster 0: [1.57104261e+00 4.25111530e+00 1.33614722e-01 3.34152181e-01\n",
      " 2.00528398e+03 6.56191831e+00 4.06097127e+00 1.71281392e+01]\n",
      "Centro del cluster 1: [1.32171828e+00 3.52171042e+00 2.16821255e-01 2.15044804e-01\n",
      " 2.00911100e+03 6.56366137e+00 3.98949851e+00 4.22643452e+00]\n",
      "Centro del cluster 2: [1.23280246e+00 4.40023506e+01 5.03214046e-02 2.25510889e-01\n",
      " 2.01175911e+03 6.47248873e+00 4.07365922e+00 1.29194570e+01]\n",
      "Centro del cluster 3: [1.39427201e+00 4.61117506e+00 1.97862282e-01 2.35978075e-01\n",
      " 2.01652549e+03 6.48013703e+00 4.04387119e+00 1.59482837e+01]\n"
     ]
    }
   ],
   "source": [
    "centros = modelo_kmeans.clusterCenters()\n",
    "for idx, centro in enumerate(centros):\n",
    "    print(f\"Centro del cluster {idx}: {centro}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b3a6ee1c-9b06-43f4-bbc9-8c1c46b750b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cluster 0:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0,0.0,1.0,0.0,...|\n",
      "|[0.0,1.0,1.0,0.0,...|\n",
      "|[0.0,2.0,1.0,0.0,...|\n",
      "|[0.0,1.0,1.0,0.0,...|\n",
      "|[0.0,1.0,1.0,0.0,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Cluster 1:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0,2.0,1.0,0.0,...|\n",
      "|[0.0,2.0,1.0,0.0,...|\n",
      "|[0.0,2.0,1.0,0.0,...|\n",
      "|[0.0,1.0,1.0,0.0,...|\n",
      "|[0.0,2.0,1.0,0.0,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Cluster 2:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0,31.0,1.0,0.0...|\n",
      "|[0.0,36.0,1.0,0.0...|\n",
      "|[0.0,27.0,1.0,0.0...|\n",
      "|[0.0,39.0,1.0,0.0...|\n",
      "|[0.0,66.0,1.0,0.0...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "\n",
      "Cluster 3:\n",
      "+--------------------+\n",
      "|            features|\n",
      "+--------------------+\n",
      "|[0.0,0.0,1.0,0.0,...|\n",
      "|[0.0,1.0,1.0,0.0,...|\n",
      "|[0.0,0.0,1.0,0.0,...|\n",
      "|[0.0,0.0,1.0,0.0,...|\n",
      "|[0.0,2.0,1.0,0.0,...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "# Ejemplo: ver los primeros 5 registros de cada cluster\n",
    "for i in range(4):\n",
    "    print(f\"\\nCluster {i}:\")\n",
    "    clusters.filter(clusters.prediction == i).select(\"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f82a1b6d-eb77-481a-83ad-79750267f539",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 300:====================================================>(138 + 2) / 140]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------+---------------+\n",
      "|prediction|             avg(ID)|         avg(label)|         avg(Beat)|     avg(District)|         avg(Ward)|avg(Community Area)| avg(X Coordinate)| avg(Y Coordinate)|         avg(Year)|     avg(Latitude)|    avg(Longitude)|avg(PrimaryType_index)|avg(LocationDesc_index)|       avg(Month)|    avg(DayOfWeek)|         avg(Hour)|avg(prediction)|\n",
      "+----------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------+---------------+\n",
      "|         1|   6652819.578038449|0.21576162065594767|1194.1507061718407|11.370557634183886|22.577080112098955| 37.567843810030084| 1164772.659464974|1885296.0604284743| 2009.113976247458|41.840845870023834|-87.67088250716252|    1.3219064954326356|      3.518364962191436|6.549960112807721|3.9892922551432006| 4.222042448961248|            1.0|\n",
      "|         3|1.0673837995250452E7|0.23457866131322527| 1143.969965235274|11.179699358566323|23.110786857954267|  36.75651748114778| 1165055.096828953|1885898.2047116647| 2016.531087499388| 41.84249183009266|-87.66982375603871|    1.3910786857954267|      4.620339812955981|6.472085393918621| 4.044440092053077|15.948078147186996|            3.0|\n",
      "|         2|   7929296.958150384|0.22499313940724477|1181.0762554884743|11.149217892425906|24.025868711701463| 35.901452775643136|1163487.4561562608|1890720.3493198466|2011.7284577387486| 41.85574179301483| -87.6754042176687|     1.228972283205269|      44.02325740944018|6.462918496158068| 4.072687980241493|12.959213776070252|            2.0|\n",
      "|         0|   4424069.552201958|0.33463992958133904|1201.8008884854487|11.251727813499295|22.503834423709854|  37.75141065578389|1164550.9089263547| 1885260.040834726|  2005.28316003741| 41.84075194605906|-87.67169646654257|    1.5733069263354789|     4.2556665016229305|6.554491940364197| 4.056417450624416|17.129016064257026|            0.0|\n",
      "+----------+--------------------+-------------------+------------------+------------------+------------------+-------------------+------------------+------------------+------------------+------------------+------------------+----------------------+-----------------------+-----------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    }
   ],
   "source": [
    "clusters.groupBy(\"prediction\").mean().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dd4160-41f3-434a-ad74-75b99a78a21e",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "\n",
    "A lo largo de esta actividad se pudo aplicar y entender de manera práctica todo el flujo de trabajo de machine learning, desde la selección y preprocesamiento de un gran volumen de datos reales, hasta la implementación de modelos tanto supervisados como no supervisados en PySpark.\n",
    "\n",
    "Aprendí la importancia de identificar y corregir registros nulos o inconsistentes, transformar tipos de datos y tratar variables categóricas correctamente para que los algoritmos puedan utilizarlas. También me di cuenta de lo fundamental que es revisar el balance entre las clases cuando se trabaja con problemas de clasificación.\n",
    "\n",
    "Respecto al modelo supervisado, aunque el árbol de decisión logró resultados perfectos, esto ocurrió principalmente por el desbalance de clases y la estructura de las variables, por lo que interpreté estos números con precaución y exploré estrategias alternativas de balanceo y análisis de métricas adicionales.\n",
    "\n",
    "En el ejercicio no supervisado con K-Means, pude observar cómo los algoritmos pueden encontrar patrones y clusters dentro de los datos sin necesidad de etiquetas, lo cual es valioso para análisis exploratorios o para entender la diversidad y estructura interna de un fenómeno complejo como el crimen en una ciudad grande.\n",
    "\n",
    "Este trabajo me permitió valorar la utilidad y los límites de los algoritmos automáticos y la relevancia crítica de un buen preprocesamiento, más allá de los valores numéricos obtenidos, la experiencia me deja aprendizajes técnicos y prácticos para abordar proyectos similares en el futuro, así como una visión más crítica sobre los retos del machine learning con big data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
